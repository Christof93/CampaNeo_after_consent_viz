\documentclass[../paper.tex]{subfiles}

\begin{document}
  % How do we evaluate our implementation?
  With the implemented prototype the following questions can be verified during a
  testing phase with real users:
  \begin{enumerate}
    \item Can we raise legal awareness of the data sharing process through
          transparent visualisation?
    \item Does the ability to constantly monitor one’s data sharing activities
          make the data processor more trustworthy to data subjects?
  \end{enumerate}
  There are several possibilities how the developed application could be
  integrated into the ecosystem of the CampaNeo project.
  One option would be to install the campaign overview natively into the
  infotainment system of modern cars. In this way a user would be the driver
  of the car who checks the status of data sharing campaigns before or after
  the drive through the on-board display of their car.

  Another equally valid option is to provide an application available
  on the web or for mobile devices which lets the owner of a car connect to
  their car and check information about campaign data sharing remotely and
  independently of accessing their car.

  To validate the posed questions, it is not essential for the test to
  take place in an actual car and simulated driving environment, since the
  application should not be used while driving anyway. For these first tests we
  provide a web application which features the functionality described in the
  previous sections. The tests can be performed on desktop computers, laptops
  or other mobile devices. The test subject needs a thorough introduction
  into the scenario since the use case of the application is very specific and
  it is very important that the situation is understood correctly.

  A good understanding is important for the test subject to tackle the
  tasks that comprise the first part of the test. After the introduction and
  before presenting the visualisation to the subject the answer to the
  following question is recorded: “Would you consider sharing sensor data
  of your car with chosen campaigns?”

  We then reveal the visualisation to the tester. The subject is presented with
  a series of simple to slightly complex tasks that revolve around answering
  questions about the privacy and extent of the data sharing activities.
  During the evaluation the test subject should be observed in real time
  through screen sharing. Using the “think aloud” method the test subject then
  informs the tester regularly about their mental process, for example what
  they want to achieve next and where they expect to find a specific information
  in the application.

  After the task solving period, the subjects are asked to fill out a
  questionnaire in which they rate their experience and explain problems or
  give suggestions for improvements.

  The goal of the questions is to find out whether the subject prefers the clear
  transparent view of all the data exchange happening or if it is more confusing
  and feels more invasive than being presented with a written contract which 
  is the prevailing method.

  In addition we want to find out if the visualisation makes subjects more
  aware of their rights and admissions within the agreement.

  The question “In the scenario where such a visualisation is available to you
  at all times, would you consider sharing sensor data of your car with chosen
  campaigns?” will show whether the approach leads to trust gains for the data
  processor.
\end{document}
